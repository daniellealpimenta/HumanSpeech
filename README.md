# ðŸŽ¤HumanSpeech - PackageðŸŽ¤

`HumanSpeech` Ã© um helper em Swift para transcrever voz em texto usando `SFSpeechRecognizer` e `AVAudioEngine`. O pacote facilita a integraÃ§Ã£o de reconhecimento de fala em apps iOS e macOS.

---

## ðŸŸ¡VisÃ£o Geral

- Coordena permissÃµes de microfone e reconhecimento de fala (locale `"pt-BR"`).  
- Inicia e para captura de Ã¡udio.  
- Publica o texto transcrito em tempo real atravÃ©s de `transcript`.  

---

## ðŸŸ¡Compatibilidade

- iOS 15+ (recomendado)  
- macOS 12+ (com microfone)

---

## ðŸŸ¡Requisitos

- **Info.plist** deve conter:
  - `NSSpeechRecognitionUsageDescription`
  - `NSMicrophoneUsageDescription`
- Frameworks:
  - `Speech`
  - `AVFoundation`

---

## ðŸŸ¡Principais VariÃ¡veis

- `transcript`: String publicada com texto parcial/final.  
- `audioEngine`: Motor de Ã¡udio em execuÃ§Ã£o.  
- `request`: Fluxo de buffers de Ã¡udio para o `SpeechRecognizer`.  
- `task`: Tarefa de reconhecimento em andamento.  
- `recognizer`: Reconhecedor configurado para `"pt-BR"`.

---

## ðŸŸ¡Principais MÃ©todos

- `startTranscribing()`: Inicia transcriÃ§Ã£o contÃ­nua.  
- `stopTranscribing()`: Encerra a captura apÃ³s 1,5s de delay.  
- `resetTranscript()`: Limpa o texto e reseta estado interno.

---

## ðŸŸ¡Como Usar

1. Crie uma instÃ¢ncia de `SpeechRecognizer`.  
2. Garanta permissÃµes (speech e microfone).  
3. Chame `startTranscribing()` para iniciar.  
4. Observe `transcript` (MainActor) para atualizar sua UI.  
5. Para encerrar, use `stopTranscribing()`.  
6. Para limpar a UI, use `resetTranscript()`.

---

## ðŸŸ¡Exemplo Simples (SwiftUI)

```swift
@State private var texto = ""
let sr = SpeechRecognizer()

var body: some View {
    VStack {
        Text(texto)
        HStack {
            Button("Iniciar") { Task { await sr.startTranscribing() } }
            Button("Parar") { Task { await sr.stopTranscribing() } }
            Button("Limpar") { Task { await sr.resetTranscript() } }
        }
    }
    .task { for await t in sr.$transcript.values { texto = t } }
}


